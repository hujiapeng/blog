1. GC优化遵循的规则：
 - 系统容量(Capacity)：就是如内存和CPU等资源情况
 - 延迟(Latency)：就是要等待的时间，如一个按钮对触发事件响应有多快、多长时间返回一个网页、查询一行SQL多长时间等
 - 吞吐量(Throughput)：一段时间内完成多少事务操作

2. 有限资源下选择垃圾回收器：
 - 如果堆大小不是很大，可以选择串行收集器，参数-XX:+UserSerialGC；
 - 如果应用运行在单核机器上，或者虚拟机是单核，依然选择串行收集器，使用参数-XX:+UserSerialGC，以为启用并行收集器没有任何收益；
 - 如果应用是“吞吐量”优先的，并且对较长时间的停顿没有什么特别要求，就选择并行收集器，使用参数-XX:+UseParallelGC;
 - 如果应用对响应时间要求高，想要较少的停顿时间，那么可以选择使用CMS、G1、ZGC，参数为-XX:+UseConcNarkSweepGC、-XX:+UseG1GC、-XX:+UseZGC。虽然收集器停顿时间短，但需要额外资源，所以通常吞吐量会低些。

3. 大流量应用的特点：对延迟非常敏感，吞吐量可以通过加机器解决，如社交、游戏、电商、支付场景等，对接口都会要求快速响应，一般不会超过100ms。长时间的停顿会堆积海量请求，所以在停顿的时候，表现会很明显。考量指标如下：
 - TPS：每秒处理的事务数量；
 - AVG：平均响应时间；
 - TP值：如TP90代表有90%的请求响应时间小于x毫秒。TP值最能代表系统有多少长尾请求，这部分请求才是影响系统稳定性的元凶。大多数情况下，GC增加，长尾请求的数量也会增加。

4. 估算：一个接口每天有10亿次请求，假如每次请求大小20KB，那么一天流量就有10亿*20/1024/1024/1024，约18TB。假如有10台机器，高峰请求每秒6万次，即每台机器6000次/秒，约每个JVM(每个机器上一个JVM)的流量达到6000*20/1024，约120MB/秒。也可以按照峰值流量的2倍粗算。
5. 调优(参数中添加-XX:+PrintGCDetails)
 如下以CMS回收器，机器为4C8GB配置，JVM每秒处理数据为120MB为例。
 初始配置，JVM堆占机器内存的2/3，即8*(2/3)*1024，约为5460MB；年轻代大小为堆空间的1/3，即5460/3，约为1820MB；如此可知Eden区大小为(1820/10)*8，约1456MB。根据JVM每秒处理数据为120MB，得出每12秒就发生一次Minor GC。也可推算出Survivor区大小约182MB，很快Survivor装不下Minor GC后的对象时，便会存到老年代。
 通过分析对象生命周期，用户每次请求完信息后，很快便变成垃圾对象，所以每次Minor GC后剩下的对象很少。如果加大年轻代空间大小，由于GC时间受活跃对象数的影响，所以回收时间并不会增加太多。修改配置如下，使年轻代堆大小为整个堆空间的一半：
 ```-XX:+UseConcMarkSweepGC -Xmx5460M -Xms5460M -Xmn2730```
 如此调整后，Minor GC有所改善，然后可以再试着调大年轻代，让对象在年轻代停留时间更长些，如修改```-Xmn3460m```，经测试Minor GC间隔又长了。
 新启动的系统，往往会导致用户请求超时等类似问题，那是因为JVM还没预热完毕，为了解决这种问题，通常做法是逐步把新发布的机器进行放量预热。如第一秒100个请求，第二秒200个请求，第三秒500个请求。大型应用都会有这个预热过程。
 MetaspaceSize不能太小，一般设置成256M。像使用Spring这种框架，都会生成大量动态类。添加参数```-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256```
6. 优化思路顺序：
 - 优先程序优化，效果通常很大；
 - 扩容，经济允许的话；
 - 参数调优，在成本、吞吐量、延迟之间找平衡点

 高并发业务下，一般对象诞生快，死亡也快，对年轻代的利用直接影响了整个堆的垃圾收集
 - 足够大的年轻代，会增加系统吞吐，但不会增加GC负担；
 - 容量足够的Survivor区，能够让对象尽可能的留在年轻代，减少对象晋升，进而减少Major GC。
 